{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JkBtSgdLtPgE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "d08adb9a-9c30-417b-8fe6-12913fb8e0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/brain-tumor-mri-dataset/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3733485915.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/input/brain-tumor-mri-dataset\"\u001b[0m  \u001b[0;31m# adjust if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_tfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_tfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtest_ds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_tfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/brain-tumor-mri-dataset/train'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============== 0) Device ==============\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ============== 1) Transforms (MRI-safe) ==============\n",
        "# Keep ImageNet normalization for ImageNet-pretrained CNNs.\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),   # <- handle grayscale MRI\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "eval_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# ============== 2) Datasets + Loaders ==============\n",
        "DATA_DIR = \"/kaggle/input/brain-tumor-mri-dataset\"  # adjust if needed\n",
        "\n",
        "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"),   transform=eval_tfms)\n",
        "test_ds  = datasets.ImageFolder(os.path.join(DATA_DIR, \"test\"),  transform=eval_tfms)\n",
        "\n",
        "num_classes = len(train_ds.classes)\n",
        "print(\"Classes:\", train_ds.classes)\n",
        "\n",
        "# Balanced sampling is helpful; but start with shuffle=True first.\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ============== 3) Model: ResNet-50 (fine-tune) ==============\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Replace classifier head\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "# ============== 4) Loss (with optional class weights) ==============\n",
        "# If your dataset is imbalanced, compute class weights from train targets:\n",
        "try:\n",
        "    counts = Counter(train_ds.targets)\n",
        "    class_weights = torch.tensor([1.0 / counts[i] for i in range(num_classes)], dtype=torch.float32, device=device)\n",
        "    class_weights = class_weights * (num_classes / class_weights.sum())  # normalize a bit\n",
        "    print(\"Class counts:\", counts)\n",
        "    print(\"Class weights:\", class_weights.cpu().numpy())\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
        "except Exception:\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "\n",
        "# ============== 5) Optimizers & Schedulers ==============\n",
        "# Phase A: train head only (warmup)\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "optimizer = optim.AdamW(model.fc.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "# ============== 6) Training helpers ==============\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "def run_epoch(model, loader, train_mode=True):\n",
        "    if train_mode:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss, total_correct, total = 0.0, 0, 0\n",
        "    pbar = tqdm(loader, leave=False)\n",
        "\n",
        "    for x, y in pbar:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "        if train_mode:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        preds = out.argmax(1)\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_correct += (preds == y).sum().item()\n",
        "        total += x.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=f\"{total_loss/total:.4f}\", acc=f\"{total_correct/total:.4f}\")\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            preds = out.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ============== 7) Training schedule ==============\n",
        "EPOCHS_HEAD   = 3   # head-only warmup\n",
        "EPOCHS_FINET  = 12  # fine-tune phase (last block + head)\n",
        "PATIENCE      = 5   # early stopping on val loss\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs_no_improve = 0\n",
        "best_path = \"best_resnet50_mri.pt\"\n",
        "\n",
        "print(\"\\n=== Phase A: Train classifier head only ===\")\n",
        "for epoch in range(1, EPOCHS_HEAD+1):\n",
        "    train_loss, train_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    val_loss,   val_acc   = run_epoch(model, val_loader,   train_mode=False)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"[Head] Epoch {epoch}/{EPOCHS_HEAD} | \"\n",
        "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
        "          f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping (head phase).\")\n",
        "            break\n",
        "\n",
        "# Unfreeze last block (layer4) for fine-tuning with lower LR\n",
        "for p in model.layer4.parameters():\n",
        "    p.requires_grad = True\n",
        "for p in model.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "optimizer = optim.AdamW([\n",
        "    {\"params\": model.fc.parameters(),     \"lr\": 1e-3},\n",
        "    {\"params\": model.layer4.parameters(), \"lr\": 1e-4},\n",
        "], weight_decay=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "print(\"\\n=== Phase B: Fine-tune layer4 + head ===\")\n",
        "epochs_no_improve = 0\n",
        "for epoch in range(1, EPOCHS_FINET+1):\n",
        "    train_loss, train_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    val_loss,   val_acc   = run_epoch(model, val_loader,   train_mode=False)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"[FT] Epoch {epoch}/{EPOCHS_FINET} | \"\n",
        "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
        "          f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping (fine-tune phase).\")\n",
        "            break\n",
        "\n",
        "# ============== 8) Load best & Test ==============\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "test_acc = evaluate_model(model, test_loader)\n",
        "print(f\"\\nBest checkpoint test accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "D5bwRJJLyHma",
        "outputId": "cf350432-0a59-409b-8bf0-f995d2cd8ab3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c709d3f7-048b-4d13-834b-2484bae9bed0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c709d3f7-048b-4d13-834b-2484bae9bed0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aminehfar\",\"key\":\"2d4f6af9b6786be61ec95dd320c3d7d2\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "AdgfD6Ym2-CP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset -p /content\n",
        "!unzip -q /content/brain-tumor-mri-dataset.zip -d /content/brain_tumor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTCj-PjfI54T",
        "outputId": "ae3e4983-7a8f-4deb-9954-f3d61f106e85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            " 87% 130M/149M [00:00<00:00, 1.35GB/s]\n",
            "100% 149M/149M [00:00<00:00, 1.35GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/brain_tumor\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN6GxoZv3GGZ",
        "outputId": "3fd7a7f6-e6ab-4e01-a926-f314c0ab4e68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Testing', 'Training']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/brain_tumor\"\n",
        "print(os.listdir(data_dir))        # ['Training', 'Testing']\n",
        "print(os.listdir(f\"{data_dir}/Training\"))  # ['glioma', 'meningioma', 'notumor', 'pituitary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42V5xpRs3KmR",
        "outputId": "21bc3fd3-673a-4335-8de2-a4f63234fbc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Testing', 'Training']\n",
            "['glioma', 'meningioma', 'notumor', 'pituitary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch.optim.lr_scheduler as lrs\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "hkKUfSebxuGm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 0) Device ==============\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjviW9LAx4W0",
        "outputId": "d78d1512-bfd2-41e2-feee-d8e7b0b29309"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 1) Transforms (MRI-safe) ==============\n",
        "# Keep ImageNet normalization for ImageNet-pretrained CNNs.\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),   # <- handle grayscale MRI safely\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "eval_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n"
      ],
      "metadata": {
        "id": "cxgZZhuHyJwp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Config ----\n",
        "DATA_DIR = \"/kaggle/input/brain-tumor-mri-dataset\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "LR = 1e-3\n",
        "NUM_WORKERS = 2"
      ],
      "metadata": {
        "id": "4mER30-f1nhy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 2) Datasets + Loaders ==============\n",
        "DATA_DIR =\"/content/brain_tumor\"\n",
        "\n",
        "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"Training\"), transform=train_tfms)\n",
        "#val_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"),   transform=eval_tfms)\n",
        "test_ds  = datasets.ImageFolder(os.path.join(DATA_DIR, \"Testing\"),  transform=eval_tfms)\n",
        "\n",
        "num_classes = len(train_ds.classes)\n",
        "print(\"Classes:\", train_ds.classes)\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "#val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv1dc15KyTtn",
        "outputId": "12f6905c-1b29-446e-b8ac-dd352681cd5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 3) Model: ResNet-50 (fine-tune) ==============\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Replace classifier head\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "H8y4hYZ-3zgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301569a2-ab66-4cf0-bab0-9d6e204eca9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 221MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 4) Loss (with optional class weights) ==============\n",
        "# If your dataset is imbalanced, compute class weights from train targets:\n",
        "try:\n",
        "    counts = Counter(train_ds.targets)\n",
        "    class_weights = torch.tensor([1.0 / counts[i] for i in range(num_classes)], dtype=torch.float32, device=device)\n",
        "    class_weights = class_weights * (num_classes / class_weights.sum())  # normalize a bit\n",
        "    print(\"Class counts:\", counts)\n",
        "    print(\"Class weights:\", class_weights.cpu().numpy())\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
        "except Exception:\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24NOdi6M4U3Q",
        "outputId": "d2b07b47-db48-44fd-b65a-37db31cd4294"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: Counter({2: 1595, 3: 1457, 1: 1339, 0: 1321})\n",
            "Class weights: [1.0748563  1.0604072  0.89021015 0.97452646]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wPnNePp8nyA",
        "outputId": "cd4ebc44-7e69-4274-86ff-6a4a3d138283"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 5) Optimizers & Schedulers ==============\n",
        "# Phase A: train head only (warmup)\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "optimizer = optim.AdamW(model.fc.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler =lrs.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n"
      ],
      "metadata": {
        "id": "pX7Ua9qT4kyW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 6) Training helpers ==============\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "def run_epoch(model, loader, train_mode=True):\n",
        "    if train_mode:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss, total_correct, total = 0.0, 0, 0\n",
        "    pbar = tqdm(loader, leave=False)\n",
        "\n",
        "    for x, y in pbar:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "        if train_mode:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        preds = out.argmax(1)\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_correct += (preds == y).sum().item()\n",
        "        total += x.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=f\"{total_loss/total:.4f}\", acc=f\"{total_correct/total:.4f}\")\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            preds = out.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uG0tPrn_k7X",
        "outputId": "8250f193-9aa0-4663-8735-bbda720e149f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2468029751.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 7) Training schedule ==============\n",
        "EPOCHS_HEAD   = 3   # head-only warmup\n",
        "EPOCHS_FINET  = 12  # fine-tune phase (last block + head)\n",
        "PATIENCE      = 5   # early stopping on test loss\n",
        "best_test_loss = float(\"inf\")\n",
        "epochs_no_improve = 0\n",
        "best_path = \"best_resnet50_mri.pt\"\n",
        "\n",
        "print(\"\\n=== Phase A: Train classifier head only ===\")\n",
        "for epoch in range(1, EPOCHS_HEAD+1):\n",
        "    train_loss, train_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    test_loss,   test_acc   = run_epoch(model, test_loader,   train_mode=False)\n",
        "    scheduler.step(test_loss)\n",
        "\n",
        "    print(f\"[Head] Epoch {epoch}/{EPOCHS_HEAD} | \"\n",
        "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
        "          f\"test_loss={test_loss:.4f} acc={test_acc:.4f}\")\n",
        "\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping (head phase).\")\n",
        "            break\n",
        "            # Unfreeze last block (layer4) for fine-tuning with lower LR\n",
        "for p in model.layer4.parameters():\n",
        "    p.requires_grad = True\n",
        "for p in model.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "optimizer = optim.AdamW([\n",
        "    {\"params\": model.fc.parameters(),     \"lr\": 1e-3},\n",
        "    {\"params\": model.layer4.parameters(), \"lr\": 1e-4},\n",
        "], weight_decay=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
        "\n",
        "print(\"\\n=== Phase B: Fine-tune layer4 + head ===\")\n",
        "epochs_no_improve = 0\n",
        "for epoch in range(1, EPOCHS_FINET+1):\n",
        "    train_loss, train_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    test_loss,   test_acc   = run_epoch(model, test_loader,   train_mode=False)\n",
        "    scheduler.step(test_loss)\n",
        "\n",
        "    print(f\"[FT] Epoch {epoch}/{EPOCHS_FINET} | \"\n",
        "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
        "          f\"test_loss={test_loss:.4f} acc={test_acc:.4f}\")\n",
        "\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping (fine-tune phase).\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZj9Y5kZISLk",
        "outputId": "769829d2-04c8-438f-bade-db180044b6d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Phase A: Train classifier head only ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/179 [00:00<?, ?it/s]/tmp/ipython-input-2468029751.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Head] Epoch 1/3 | train_loss=0.7131 acc=0.7771 | test_loss=0.6176 acc=0.8246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Head] Epoch 2/3 | train_loss=0.5578 acc=0.8515 | test_loss=0.5768 acc=0.8413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Head] Epoch 3/3 | train_loss=0.5391 acc=0.8601 | test_loss=0.5812 acc=0.8406\n",
            "\n",
            "=== Phase B: Fine-tune layer4 + head ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 1/12 | train_loss=0.4569 acc=0.9046 | test_loss=0.3374 acc=0.9497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 2/12 | train_loss=0.3153 acc=0.9667 | test_loss=0.3185 acc=0.9718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 3/12 | train_loss=0.2851 acc=0.9776 | test_loss=0.2988 acc=0.9771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 4/12 | train_loss=0.2646 acc=0.9883 | test_loss=0.2587 acc=0.9863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 5/12 | train_loss=0.2465 acc=0.9921 | test_loss=0.2474 acc=0.9901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 6/12 | train_loss=0.2369 acc=0.9951 | test_loss=0.2328 acc=0.9954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 7/12 | train_loss=0.2318 acc=0.9970 | test_loss=0.2259 acc=0.9969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 8/12 | train_loss=0.2275 acc=0.9972 | test_loss=0.2246 acc=0.9985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 9/12 | train_loss=0.2318 acc=0.9958 | test_loss=0.2269 acc=0.9954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 10/12 | train_loss=0.2312 acc=0.9958 | test_loss=0.2250 acc=0.9992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 11/12 | train_loss=0.2245 acc=0.9977 | test_loss=0.2219 acc=0.9931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 12/12 | train_loss=0.2289 acc=0.9960 | test_loss=0.2336 acc=0.9908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== 8) Load best & Test ==============\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "test_acc = evaluate_model(model, test_loader)\n",
        "print(f\"\\nBest checkpoint test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKDNF_x9IVVp",
        "outputId": "cab4cf4e-d32a-4673-cd61-06ea9127af8b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best checkpoint test accuracy: 0.9931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgfoYEPSUYsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(model, loader, class_names):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = model(x)\n",
        "            preds = outputs.argmax(1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(6,6))\n",
        "    disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=False)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Usage (after training, use validation or test loader)\n",
        "plot_confusion_matrix(model, test_loader, train_ds.classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "20pwQ_SNNUcF",
        "outputId": "fc950097-cd8a-4222-de1a-377799fe7546"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}